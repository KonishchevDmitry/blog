<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Dmitry Konishchev&#39;s small blog</title>
    <link>https://konishchev.ru/</link>
    <description>Recent content on Dmitry Konishchev&#39;s small blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ru</language>
    <lastBuildDate>Sat, 18 May 2024 17:05:01 +0300</lastBuildDate>
    <atom:link href="https://konishchev.ru/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BBR: когда TCP &#34;быстрее&#34; UDP</title>
      <link>https://konishchev.ru/posts/tcp-bbr/</link>
      <pubDate>Fri, 19 Apr 2024 21:25:58 +0300</pubDate>
      
      <guid>https://konishchev.ru/posts/tcp-bbr/</guid>
      <description>Некоторое время назад, в связи со всем известными событиями, я решил защитить свой текущий тоннель до VPS в Нидерландах, для которого до этого использовал обычный WireGuard. Как это часто со мной бывает, я решил пойти не самым простым, но зато самым любимым мной путём – и написал свой тоннель. :) Идея эта была привлекательна тем, что давала мне возможность познакомиться с Tokio, побольше узнать о принципах работы tun/tap–интерфейсов в Linux, почитать исходники Shadowsocks, ну и в процессе даже удалось найти и поправить небольшую багу в networkd.</description>
      <content:encoded><![CDATA[<p>Некоторое время назад, в связи со всем известными событиями, я решил защитить свой текущий тоннель до VPS в Нидерландах, для которого до этого использовал обычный <a href="https://www.wireguard.com/">WireGuard</a>. Как это часто со мной бывает, я решил пойти не самым простым, но зато самым любимым мной путём – и написал свой тоннель. :) Идея эта была привлекательна тем, что давала мне возможность познакомиться с <a href="https://tokio.rs/">Tokio</a>, побольше узнать о принципах работы tun/tap–интерфейсов в Linux, почитать исходники <a href="https://shadowsocks.org/">Shadowsocks</a>, ну и в процессе даже удалось найти и поправить <a href="https://github.com/systemd/systemd/pull/30504">небольшую багу в networkd</a>. Но на самом деле речь в данном посте пойдёт не об этом.</p>
<p>Когда я писал свой тоннель, у меня было стойкое убеждение, что в качестве транспорта нужно прежде всего ориентироваться на UDP, а на TCP откатываться только в том случае, когда UDP перестаёт работать в силу тех или иных &ldquo;причин&rdquo;. И это вроде бы логично: в плане производительности для тоннеля UDP всегда предпочтительнее, т. к. он реализует именно то, что нам нужно – максимально тонкую обёртку над пакетами, а с TCP у нас начинается целый ворох проблем, начиная с <a href="https://openvpn.net/faq/what-is-tcp-meltdown/">TCP Meltdown</a> и заканчивая <a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">head-of-line blocking</a>.</p>
<p>Но вот когда я начал думать, как можно подтюнить получившийся тоннель помимо включения довольно очевидных вещей вроде <a href="https://man7.org/linux/man-pages/man7/tcp.7.html">TCP_NODELAY</a>, то набрёл на BBR, который стал для меня очень приятным открытием.</p>
<h2 id="bbr">BBR</h2>
<p><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=0f8782ea14974ce992618b55f0c041ef43ed0b78">BBR (Bottleneck Bandwidth and RTT)</a> – это алгоритм <a href="https://en.wikipedia.org/wiki/TCP_congestion_control">TCP congestion control</a>, разработанный в Google. В отличие от традиционных алгоритмов, которые ориентируются на потери пакетов, BBR пытается судить о загруженности канала, наблюдая за тем, как меняется скорость передачи данных и RTT. Сейчас сети уже не те, что были в 80-ых годах, и такой подход работает гораздо лучше, а особенно – в случае трансконтинентальных соединений, где у нас может быть довольно широкий канал, но при этом небольшой процент потерь пакетов является нормой (как в моём случае с дешёвым VPS).</p>
<p>В результате получается, что если у вас такой канал, где нередки небольшие потери пакетов, то это сильно сказывается на скорости TCP-соединения, т. к. эти потери расцениваются традиционными алгоритмами как сигнал к тому, что необходимо сбросить скорость до тех пор, пока они не сойдут на нет. К тому же, даже в случае когда потерь нет, но при этом TCP-соединение способно утилизировать весь канал передачи данных, традиционные алгоритмы склонны снижать скорость только тогда, когда буфер роутера (зачастую довольно большой) уже переполнен, и роутер начинает дропать пакеты, что по факту является сильно запоздалой реакцией, которая приводит к увеличению latency, а BBR как раз пытается этой ситуации избежать. Этой проблеме даже посвящен целый сайт <a href="https://www.bufferbloat.net/projects/">bufferbloat.net</a>.</p>
<p>Польза, которую BBR способен вам нанести по сравнению со стандартным CUBIC&rsquo;ом, сильно зависит от многих факторов, но вот, к примеру, отчёты Amazon и Google, которые свидетельствуют о том, что после включения BBR у них стабильно улучшились bandwidth и RTT: <a href="https://aws.amazon.com/blogs/networking-and-content-delivery/tcp-bbr-congestion-control-with-amazon-cloudfront/">Amazon</a>, <a href="https://cloud.google.com/blog/products/networking/tcp-bbr-congestion-control-comes-to-gcp-your-internet-just-got-faster">Google</a>. В определённых случаях можно ожидать и кратного увеличения скорости TCP-соединения.</p>
<p>Т. к. BBR является алгоритмом TCP congestion control, то включается он на отправляющей стороне. Т. е., включив его на своём ноутбуке, вы улучшите upload данных, а чтобы улучшить download, он должен быть включён на сервере. При этом, само собой, включение его на одной стороне не требует какой-либо поддержки на другой, т. к. меняются только эвристики внутри TCP-протокола, а не сам протокол.</p>
<h2 id="критика">Критика</h2>
<p>Не обошлось правда и без <a href="https://huitema.wordpress.com/2019/01/12/will-transport-innovation-collapse-the-internet/">критики</a> данного алгоритма. Всё дело в том, что по сравнению со стандартным CUBIC&rsquo;ом, BBR ведёт себя достаточно агрессивно, и может получиться так, что если вы, скажем, включите его на своем Linux-ноутбуке и начнёте заливать большие файлы в сеть, то ваш BBR-ноутбук может запросто &ldquo;задушить&rdquo; TCP-соединения соседних устройств, использующих традиционные алгоритмы TCP congestion control (а в MacOS, к примеру, BBR и вовсе недоступен).</p>
<p>Есть инициатива в виде <a href="https://datatracker.ietf.org/meeting/112/materials/slides-112-iccrg-bbrv2-update-00">BBRv2</a>, которая пытается решить эту проблему, но пока что в ядре используется первая версия, и надо эту особенность иметь в виду.</p>
<h2 id="эффект-от-bbr-применительно-к-tcp-тоннелю">Эффект от BBR применительно к TCP-тоннелю</h2>
<p>Так вот, почитав всё это, я с одной стороны обрадовался (какая многообещающая штука – надо пробовать!), а с другой – тут же взгрустнул: включать BBR нужно на конечных устройствах (сервер + клиент), а на роутере его включать бесполезно, т. к. при forwarding&rsquo;е пакетов все эти алгоритмы по понятным причинам не задействованы. Но на серверную часть я повлиять не могу, а в качестве клиентской у меня ноутбук с MacOS, в котором BBR и вовсе нет. С другой стороны – подумал я – у меня ведь по факту два TCP-соединения: одно между ноутбуком и конечным сервером, а другое – между двумя точками тоннеля, которые находятся на Linux-серверах, и вот на это соединение я повлиять могу.</p>
<p>Чтож, попробуем&hellip; Включил его для TCP-соединения своего тоннеля – и тут же получил 2.5x скорость при скачивании файлов! Если раньше что с UDP, что с TCP-транспортом у меня абсолютным максимумом было 30 Mbit/s, то после включения BBR оно тут же скакнуло до 75 Mbit/s.</p>
<p>Лично я такие результаты объясняю себе следующим: гоняя тоннельный траффик по TCP, я маскирую все потери пакетов между двумя точками тоннеля для TCP-соединений, которые в него заворачиваются. И даже если они используют традиционные алгоритмы, основанные на потерях пакетов, то теперь они этих потерь не замечают и не сбрасывают скорость почём зря. Ну а дальше уже эти данные передаются по TCP-соединению тоннеля с BBR, который максимизирует скорость передачи данных.</p>
<p>В итоге я пришёл к следующему: если раньше я всегда в качестве транспорта использовал UDP, и переключение на TCP вызывало заметные глазу подтормаживания при загрузке страниц в браузере, то теперь, когда у меня TCP работает с BBR, картина поменялась на противоположную: UDP выдаёт вполне приемлемый результат, но если переключиться на TCP, то невооружённым глазом становится видно, что всё начинает подгружаться ещё быстрее. Учитывая то, что TCP-тоннель ещё и можно замаскировать под обычное HTTPS-соединение, получается, что в использовании UDP и вовсе нет смысла. Единственное, в чём UDP по прежнему обходит TCP + BBR – это в latency: если запустить ping и начать грузить канал, то в случае с UDP latency ping&rsquo;ов практически не меняется, в то время как с TCP (с BBR и без) оно может увеличиваться до четырёх раз. Но т. к. это довольно синтетический тест, а при реальном использовании с браузером, как я описал выше, я вижу противоположные результаты, то для меня это не выглядит проблемой.</p>
<h2 id="включение">Включение</h2>
<p>Включается BBR очень просто:</p>
<p><code>sysctl net.ipv4.tcp_available_congestion_control</code> показывает список доступных алгоритмов. Скорее всего, по умолчанию BBR там не будет:</p>
<pre tabindex="0"><code>$ sudo sysctl net.ipv4.tcp_available_congestion_control
net.ipv4.tcp_available_congestion_control = reno cubic
</code></pre><p>– это потому, что не загружен соответствующий модуль ядра.</p>
<ol>
<li>Загружаем модуль – <code>modprobe tcp_bbr</code> (или <code>echo tcp_bbr &gt; /etc/modules-load.d/bbr.conf</code>, чтобы он загружался автоматом при старте системы).</li>
<li>Включаем BBR – <code>sysctl net.ipv4.tcp_congestion_control=bbr</code> (или <code>echo 'net.ipv4.tcp_congestion_control = bbr' &gt; /etc/sysctl.d/bbr.conf</code>, чтобы он включался автоматом при старте системы). На всякий случай замечу, что, несмотря на префикс <code>net.ipv4.*</code>, включение происходит как для IPv4, так и для IPv6.</li>
</ol>
<p>При этом его можно включить не для всех, а только для отдельных TCP-соединений, передав опцию <a href="https://man7.org/linux/man-pages/man7/tcp.7.html">TCP_CONGESTION</a> в <a href="https://man7.org/linux/man-pages/man2/setsockopt.2.html">setsockopt(2)</a>. И даже у <code>iperf</code> есть опция <code>-C bbr</code>, с помощью которой можно протестировать поведение различных алгоритмов TCP congestion control конкретно для вашего случая.</p>
<h2 id="last-but-not-least">Last, but not least</h2>
<p>В процессе изучения всего вышеописанного я абсолютно случайно для себя узнал, что в то время как во всех современных дистрибутивах благодаря systemd уже давно в качестве <a href="https://www.linuxjournal.com/content/queueing-linux-network-stack">queueing discipline</a> по умолчанию включена <code>fq_codel</code>, которая считается наиболее оптимальным general purpose вариантом, то в Debian/Ubuntu меинтейнеры не смогли преодолеть свою внутреннюю бюрократию – и даже в самых современных Debian/Ubuntu по умолчанию используется <code>pfifo_fast</code>: они не включают в systemd-пакет его <a href="https://github.com/systemd/systemd/blob/main/sysctl.d/50-default.conf">стандартный конфиг</a>, но в то же время не смогли найти &ldquo;правильное место&rdquo;, куда можно было бы положить аналогичные разумные default&rsquo;ы – и в результате используется значение по умолчанию, которое установлено в ядре.</p>
<p><code>pfifo_fast</code> – это самая простая queueing discipline, которая никак не приоритезирует пакеты между различными сетевыми соединениями, и может получиться так, что самое активное из них будет сильно увеличивать latency всех остальных.</p>
<p>Поэтому рекомендую всем пользователям Debian/Ubuntu добавить <code>/etc/sysctl.d/00-qdisc.conf</code> со следующим содержимым:</p>
<pre tabindex="0"><code>net.core.default_qdisc = fq_codel
</code></pre><p>чтобы исправить это недоразумение.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>gmailctl: наводим порядок в своей почте</title>
      <link>https://konishchev.ru/posts/gmailctl/</link>
      <pubDate>Mon, 08 Apr 2024 19:25:58 +0300</pubDate>
      
      <guid>https://konishchev.ru/posts/gmailctl/</guid>
      <description>У меня довольно большое количество фильтров в Gmail, которое уже давно не влезает на один экран монитора, и при этом интерфейс управления этими фильтрами в Gmail настолько примитивен, что не даёт абсолютно никаких возможностей их хоть как-то организовать. Поэтому каждый раз, когда раньше возникала необходимость добавить новый фильтр (а гораздо хуже – изменить существующий), я мысленно вздыхал – и шёл в этот ужасно неудобный интерфейс&amp;hellip; пока случайно не наткнулся на gmailctl.</description>
      <content:encoded><![CDATA[<p>У меня довольно большое количество фильтров в Gmail, которое уже давно не влезает на один экран монитора, и при этом интерфейс управления этими фильтрами в Gmail настолько примитивен, что не даёт абсолютно никаких возможностей их хоть как-то организовать. Поэтому каждый раз, когда раньше возникала необходимость добавить новый фильтр (а гораздо хуже – изменить существующий), я мысленно вздыхал – и шёл в этот ужасно неудобный интерфейс&hellip; пока случайно не наткнулся на gmailctl.</p>
<p><a href="https://github.com/mbrt/gmailctl">gmailctl</a> – это абсолютно потрясающая утилитка, которая позволяет вовсе не использовать web-интерфейс редактирования правил обработки почты и унести их в локальный конфиг. У неё свой язык описания правил (имеющий свои преимущества), который она затем преобразовывает в формат Gmail и заменяет все существующие фильтры на описанные в вашем конфиге (не забыв при этом показать аккуратный diff изменений).</p>
<p>Правила могут быть как очень простые:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-js" data-lang="js"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  filter: {from: <span style="color:#a31515">&#34;linkedin.com&#34;</span>},
</span></span><span style="display:flex;"><span>  actions: label(<span style="color:#a31515">&#34;LinkedIn&#34;</span>),
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>так и довольно развесистые:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-js" data-lang="js"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  filter: {or: [
</span></span><span style="display:flex;"><span>    {and: [{from: <span style="color:#a31515">&#34;notifications@github.com&#34;</span>}, {subject: <span style="color:#a31515">&#34;[KonishchevDmitry/&#34;</span>}, {subject: <span style="color:#a31515">&#34;] Release&#34;</span>}]},
</span></span><span style="display:flex;"><span>    {and: [{from: <span style="color:#a31515">&#34;cloud@support.yandex.ru&#34;</span>}, {or: [
</span></span><span style="display:flex;"><span>      {subject: <span style="color:#a31515">&#34;You have been given a grant&#34;</span>},
</span></span><span style="display:flex;"><span>      {subject: <span style="color:#a31515">&#34;Planned maintenance&#34;</span>},
</span></span><span style="display:flex;"><span>    ]}]},
</span></span><span style="display:flex;"><span>    {and: [{from: <span style="color:#a31515">&#34;noreply@market.yandex.ru&#34;</span>}, {or: [
</span></span><span style="display:flex;"><span>      {subject: <span style="color:#a31515">&#34;Вы оформили и оплатили заказ&#34;</span>},
</span></span><span style="display:flex;"><span>      {and: [{subject: <span style="color:#a31515">&#34;Заказ&#34;</span>}, {subject: <span style="color:#a31515">&#34;доставлен&#34;</span>}]},
</span></span><span style="display:flex;"><span>    ]}]},
</span></span><span style="display:flex;"><span>    {and: [{from: <span style="color:#a31515">&#34;mailer@sender.ozon.ru&#34;</span>}, {subject: <span style="color:#a31515">&#34;Вам понравился заказ?&#34;</span>}]},
</span></span><span style="display:flex;"><span>    {and: [{from: <span style="color:#a31515">&#34;mosenergosbyt.ru&#34;</span>}, {subject: <span style="color:#a31515">&#34;Электронный счёт за&#34;</span>}]},
</span></span><span style="display:flex;"><span>  ]},
</span></span><span style="display:flex;"><span>  actions: <span style="color:#00f">delete</span>(),
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Увидев это чудо, я в тот же день переколбасил все свои правила и полностью перешел на gmailctl. Они по-прежнему занимают несколько экранов монитора, но зато теперь их можно организовать удобным мне образом, объявлять функции и переменные, ставить комментарии, отделять отступами и т. п. В общем, всё как в любых нормальных декларативных языках.</p>
<p>Крайне рекомендую. Невероятно полезная и удобная вещь для всех, у кого больше десятка фильтров в Gmail.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Проблемы обратной совместимости glibc</title>
      <link>https://konishchev.ru/posts/glibc-static-linking/</link>
      <pubDate>Wed, 27 Mar 2024 21:57:31 +0300</pubDate>
      
      <guid>https://konishchev.ru/posts/glibc-static-linking/</guid>
      <description>В своей работе я не раз сталкивался с тем, что, собрав Go/Rust-программу на своей рабочей машине и скопировав её на другую, с более старой версией дистрибутива, есть большой шанс того, что она при запуске упадёт с ошибкой вида /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.38&#39; not found. Обычно разбираться всегда было некогда, и я просто пересобирал свою программу на нужной версии дистрибутива, но вот тут стало интересно – и я пошёл посмотреть, как скомпилить свою Rust&amp;rsquo;овую программу статически с glibc, чтобы не иметь таких проблем.</description>
      <content:encoded><![CDATA[<p>В своей работе я не раз сталкивался с тем, что, собрав Go/Rust-программу на своей рабочей машине и скопировав её на другую, с более старой версией дистрибутива, есть большой шанс того, что она при запуске упадёт с ошибкой вида <code>/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.38' not found</code>. Обычно разбираться всегда было некогда, и я просто пересобирал свою программу на нужной версии дистрибутива, но вот тут стало интересно – и я пошёл посмотреть, как скомпилить свою Rust&rsquo;овую программу статически с glibc, чтобы не иметь таких проблем. В результате узнал для себя что-то новое и делюсь своими находками.</p>
<h2 id="glibc">glibc</h2>
<p>Первая мысль была довольно предсказуемой и понятной: &ldquo;пойду-ка посмотрю, как собрать статически Rust&rsquo;овый бинарь с glibc&rdquo; – и, на самом деле, особых проблем с этим нет. Надо всего лишь сделать вот так:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>RUSTFLAGS=<span style="color:#a31515">&#39;-C target-feature=+crt-static&#39;</span> cargo build --release --target x86_64-unknown-linux-gnu
</span></span></code></pre></div><p>– и оно работает, программа запускается без проблем!</p>
<p>Но, если покопать эту тему чуть более подробно, то выясняется, что решение это на самом деле – так себе. Всё дело в том, что glibc так устроена, что она в принципе не особо предназначена для статической линковки: из-за <a href="http://man7.org/linux/man-pages/man5/nsswitch.conf.5.html">NSS</a>, <a href="http://man7.org/linux/man-pages/man3/iconv.3.html"><code>iconv(3)</code></a> и пр. она полагается на <a href="http://man7.org/linux/man-pages/man3/dlopen.3.html"><code>dlopen(3)</code></a>, и определённые функции стандартной библиотеки могут стриггерить, скажем, загрузку NSS-модуля, который является динамически разделяемой библиотекой, к тому же динамически слинкованной с glibc, что в свою очередь может привести к ситуации, когда у нас в адресном пространстве приложения будут загружены две glibc: статическая и динамически подгруженная через зависимость NSS-модуля, что в итоге может привести к разным интересным последствиям (к примеру, как они будут делить буферы <code>stdout</code>?). Внутри неё на самом деле есть различные подпорки, чтобы статическая сборка всё-таки нормально работала в большинстве случаев, но вот только гарантий, что она будет работать во всех возможных сценариях – нет.</p>
<p>В итоге, большинство людей сходятся в том, что статическую сборку с glibc лучше не использовать, т. к. мы тут идём против её дизайна и рискуем получить неожиданные последствия от таких действий. И самый оптимальный вариант тут – использовать для сборки Docker-контейнер с каким-нибудь заведомо не самым свежим LTS-дистрибутивом – и линковаться против glibc его версии.</p>
<p>Но также есть и другие варианты.</p>
<h2 id="musl">musl</h2>
<p>Напомню, что Linux – это только ядро, а не операционная система. Интерфейсом к ядру являются системные вызовы, и поэтому ничто не мешает нам вместо glibc использовать что-то другое. Наиболее распространённом вариантом в данном случае является <a href="https://musl.libc.org/">musl</a>.</p>
<p>Честно говоря, я musl до этого момента ни разу не пользовался, т. к. мне всегда казалось довольно странным использовать что-то нестандартное вместо glibc – обязательно ведь где-нибудь что-нибудь будет работать по-другому, и можно нарваться на какие-нибудь неприятные сюрпризы в самый неподходящий на то момент. Поэтому всегда считал, что её использование имеет смысл разве что в embedded, либо где-нибудь вроде <a href="https://www.alpinelinux.org/">Alpine</a>, где нам по какой-то причине хочется получить максимально компактный образ.</p>
<p>Но если смотреть с позиции статической линковки, использование musl вполне имеет смысл, т. к. для неё, в отличие от glibc, статическая линковка является абсолютно стандартным вариантом использования.</p>
<p>Поэтому (в случае Rust) выполняем:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>rustup target add x86_64-unknown-linux-musl
</span></span><span style="display:flex;"><span>cargo build --target x86_64-unknown-linux-musl
</span></span></code></pre></div><p>– и получаем то, что нам нужно. Правда, свои &ldquo;но&rdquo; тут тоже есть&hellip;</p>
<p>musl ставит своей целью быть компактной и простой в реализации, и, как это часто бывает, когда кто-то ставит себе такую цель, то порой оказывается, что некоторые вещи в принципе не должны быть простыми, и слишком простая их реализация приводит к проблемам.</p>
<p>В результате чего нередки ситуации, когда наша программа, которая без проблем работала с glibc, вдруг перестаёт работать из-за того, что <a href="https://purplecarrot.co.uk/post/2021-09-04-does_alpine-resolve_dns_properly/">в musl DNS resolver не поддерживает ответы с большим количеством записей</a> (на самом деле уже <a href="https://www.furorteutonicus.eu/2023-10-02-musl-alpine-dns">исправлено</a>), либо работает в десятки (!) раз медленнее – <a href="https://www.linkedin.com/pulse/testing-alternative-c-memory-allocators-pt-2-musl-mystery-gomes/">раз</a>, <a href="https://andygrove.io/2020/05/why-musl-extremely-slow/">два</a>, <a href="https://twitter.com/theomn/status/1149853793636368384">три</a> (как правило, в случае интенсивной аллокации памяти из нескольких потоков одновременно, но также это может быть связано и с тем, что &ldquo;раздутая&rdquo; glibc использует AVX и прочие инструкции для оптимизации своих функций, а &ldquo;простая и компактная&rdquo; musl – нет), либо у вас какая-то специфическая конфигурация, в которой проявляются <a href="https://github.com/gliderlabs/docker-alpine/blob/460819debdada8db435a3619c688a702bdd3420b/docs/caveats.md">отличия в реализации glibc и musl</a>. Ну и, понятное дело, musl не подойдет, если вам нужен NSS (к примеру, в случае с LDAP).</p>
<p>В итоге, я бы сказал, что если у вас в качестве приложения довольно простая command line-утилита, то скорее всего проблем не будет – и для простоты можно статически линковаться с musl, но если у вас какой-то навороченный/высоконагруженный сервис, то либо стоит быть готовым к сюрпризам, либо использовать более сложную конфигурацию вроде musl + <a href="https://github.com/microsoft/mimalloc">mimalloc</a>/<a href="https://jemalloc.net/">jemalloc</a> в качестве аллокатора.</p>
<h2 id="eyra">Eyra</h2>
<p>Если говорить о Rust, то на самом деле есть ещё один интересный вариант – <a href="https://github.com/sunfishcode/eyra/">Eyra</a>. Данный проект ставит своей целью реализовать все функции стандартной библиотеки на Rust и линковаться в процессе сборки с ними.</p>
<p>Этот вариант я, честно говоря, даже не пробовал (уж больно молодой проект), но идея интересная и многообещающая.</p>
<h2 id="интересный-факт">Интересный факт</h2>
<p>Я этого не знал, но, оказывается, ABI системных вызовов стабильный только у Linux. В Windows и MacOS он может меняться абсолютно непредсказуемым образом (даже в минорных версиях), и стабильным является только API стандартной библиотеки (<code>ntdll.dll</code> в Windows и <code>libSystem.dylib</code> в MacOS). И там такой опции у нас вовсе нет.</p>
<p>Go даже поначалу пытался идти тут против течения, но в итоге <a href="https://golang.org/doc/go1.11#runtime">сдался</a>.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Перезапуск блога</title>
      <link>https://konishchev.ru/posts/blog-again/</link>
      <pubDate>Tue, 26 Mar 2024 13:23:06 +0300</pubDate>
      
      <guid>https://konishchev.ru/posts/blog-again/</guid>
      <description>Больше 11 лет прошло с момента моего последнего поста в блоге KonishchevDmitry&amp;rsquo;s small blog, который я вёл когда-то давно и достаточно активно.
И вот какое-то время назад появилось желание попробовать его возродить в том или ином виде, т. к. всё равно время от времени появляются мысли, которыми хотелось бы поделиться в силу того, что они могут быть кому-то полезны. Причём сейчас такое интересное время, что даже если твой пост не смог пробиться сквозь поисковую выдачу, то кто знает – может какая-то его часть сможет обогатить базу знаний условного ChatGPT, и он потом на какие-то вопросы будет отвечать в своей уверенной манере фразами из твоего блога, тем самым таргетированно нанося кому-то пользу.</description>
      <content:encoded><![CDATA[<p>Больше 11 лет прошло с момента моего последнего поста в блоге <a href="https://konishchevdmitry.blogspot.com/">KonishchevDmitry&rsquo;s small blog</a>, который я вёл когда-то давно и достаточно активно.</p>
<p>И вот какое-то время назад появилось желание попробовать его возродить в том или ином виде, т. к. всё равно время от времени появляются мысли, которыми хотелось бы поделиться в силу того, что они могут быть кому-то полезны. Причём сейчас такое интересное время, что даже если твой пост не смог пробиться сквозь поисковую выдачу, то кто знает – может какая-то его часть сможет обогатить базу знаний условного ChatGPT, и он потом на какие-то вопросы будет отвечать в своей уверенной манере фразами из твоего блога, тем самым таргетированно нанося кому-то пользу. :)</p>
<p>Свободного времени у меня теперь заметно меньше чем раньше, и вряд ли я буду писать сюда часто, но раз желание появилось – то надо попробовать, а там уж посмотрим, что из этого выйдет.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
